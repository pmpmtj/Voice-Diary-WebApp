"""
Configuration settings for transcription models.
This file contains settings for different transcription models:
1. Local Whisper (using local model files)
2. OpenAI Whisper API (whisper-1)
3. OpenAI 4o Transcribe API
"""

# Transcription model configuration
TRANSCRIBE_CONFIG = {
    # The type of transcription model to use
    "model_type": "local",  # Options: "local", "whisper-1", "4o-transcribe"
    
    # OpenAI API configuration (when using whisper-1 or 4o-transcribe)
    "api_key": "",  # Set your API key here or use environment variable OPENAI_API_KEY
    
    # Local Whisper model configuration (when using local)
    "local_model": {
        "model_name": "base",  # Options: "tiny", "base", "small", "medium", "large"
        "model_directory": "./model",  # Directory where local models are stored
        "device": "cuda" if "cuda" in dir() else "cpu",  # Use cuda if available
    },
    
    # OpenAI Whisper-1 API configuration (when using whisper-1)
    "whisper_api": {
        "model": "whisper-1",
        "language": None,  # Optional language code (e.g., "en")
        "prompt": "",  # Optional prompt to guide the model
        "response_format": "text",  # Options: "text", "vtt", "srt", "verbose_json", "json"
        "temperature": 0.0,  # Lower values = more deterministic
    },
    
    # OpenAI 4o Transcribe API configuration (when using 4o-transcribe)
    "4o_transcribe": {
        "model": "gpt-4o",  # The model to use for transcription
        "language": None,  # Optional language code
        "prompt": "",  # Optional prompt to guide the model
        "response_format": "text",  # Response format for the transcription
        "temperature": 0.0,  # Lower values = more deterministic
    },
    
    # Common settings
    "chunk_audio": False,  # Whether to chunk audio files for better accuracy
    "max_chunk_size": 24 * 60 * 1000,  # Maximum size of audio chunks in milliseconds (24 mins)
    "vad_filter": False,  # Voice activity detection to filter silence
    "vad_threshold": 0.5,  # Threshold for voice activity detection
}

# Transcription output configuration
OUTPUT_CONFIG = {
    "output_format": "text",  # Options: "text", "json", "vtt", "srt"
    "output_file": "transcription.txt",  # Default output file
    "timestamps": False,  # Whether to include timestamps
    "word_timestamps": False,  # Whether to include word-level timestamps (only available with certain models)
    "append_output": False,  # Whether to append to existing output file
}

# Meta-information about model capabilities
MODEL_CAPABILITIES = {
    "local": {
        "languages": ["en", "zh", "de", "es", "ru", "ko", "fr", "ja", "pt", "tr", "pl", "ca", "nl", "ar", "sv", "it", "id", "hi", "fi", "vi", "he", "uk", "el", "ms", "cs", "ro", "da", "hu", "ta", "no", "th", "ur", "hr", "bg", "lt", "la", "mi", "ml", "cy", "sk", "te", "fa", "lv", "bn", "sr", "az", "sl", "kn", "et", "mk", "br", "eu", "is", "hy", "ne", "mn", "bs", "kk", "sq", "sw", "gl", "mr", "pa", "si", "km", "sn", "yo", "so", "af", "oc", "ka", "be", "tg", "sd", "gu", "am", "yi", "lo", "uz", "fo", "ht", "ps", "tk", "nn", "mt", "sa", "lb", "my", "bo", "tl", "mg", "as", "tt", "haw", "ln", "ha", "ba", "jw", "su"],
        "supports_word_timestamps": True,
        "max_input_length": "25 minutes",
        "chunk_size_required": True,
    },
    "whisper-1": {
        "languages": ["all languages"],
        "supports_word_timestamps": True,
        "max_input_length": "25 minutes",
        "chunk_size_required": False,
    },
    "4o-transcribe": {
        "languages": ["all languages"],
        "supports_word_timestamps": True, 
        "max_input_length": "4 hours",
        "chunk_size_required": False,
    }
} 